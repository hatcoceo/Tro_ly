# sd1: há»c vÄƒn báº£n du_lieu.txt
# sd : dá»± Ä‘oÃ¡n tá»« t
import re
import os
import json
import random
from collections import defaultdict, Counter

MODEL_PATH = "char_markov_model2.json"

plugin_info = {
    "enabled": True,
    "register": lambda assistant: assistant.handlers.insert(1, NextCharWordPredictorHandler(assistant)),
    "methods": [],
    "classes": []
}

class NextCharWordPredictorHandler:
    def __init__(self, assistant):
        self.assistant = assistant
        self.model = defaultdict(Counter)  # model[prefix] = {next_char: count}
        self.words = set()
        self._load_model()

    def _tokenize_words(self, text):
        # TÃ¡ch tá»« gá»“m chá»¯ cÃ¡i tiáº¿ng Viá»‡t (khÃ´ng láº¥y sá»‘, dáº¥u cÃ¢u)
        return re.findall(r"\b\w+\b", text.lower())

    def _build_char_model_from_words(self, word_list):
        for word in word_list:
            if len(word) < 2:
                continue
            self.words.add(word)
            for i in range(1, len(word)):
                prefix = word[:i]
                next_char = word[i]
                self.model[prefix][next_char] += 1

    def _predict_word(self, prefix, max_len=20):
        result = prefix
        for _ in range(max_len):
            options = self.model.get(result)
            if not options:
                break
            next_char = random.choices(list(options.keys()), weights=options.values())[0]
            result += next_char
            if result in self.words:
                return result
        return result  # Tráº£ vá» náº¿u khÃ´ng khá»›p tá»« hoÃ n chá»‰nh

    def _save_model(self):
        try:
            data = {
                "model": {k: dict(v) for k, v in self.model.items()},
                "words": list(self.words)
            }
            with open(MODEL_PATH, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o '{MODEL_PATH}'")
        except Exception as e:
            print(f"âŒ KhÃ´ng thá»ƒ lÆ°u mÃ´ hÃ¬nh: {e}")

    def _load_model(self):
        if os.path.exists(MODEL_PATH):
            try:
                with open(MODEL_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                self.words = set(data.get("words", []))
                for prefix, counter in data.get("model", {}).items():
                    self.model[prefix] = Counter(counter)
                print(f"ğŸ“¥ ÄÃ£ náº¡p mÃ´ hÃ¬nh tá»« '{MODEL_PATH}'")
            except Exception as e:
                print(f"âš ï¸ KhÃ´ng thá»ƒ náº¡p mÃ´ hÃ¬nh: {e}")

    def can_handle(self, command: str) -> bool:
        return command.startswith("há»c vÄƒn báº£n ") or command.startswith("dá»± Ä‘oÃ¡n tá»« ")

    def handle(self, command: str) -> bool:
        if command.startswith("há»c vÄƒn báº£n "):
            path = command[len("há»c vÄƒn báº£n "):].strip()
            try:
                with open(path, "r", encoding="utf-8") as f:
                    text = f.read()
                word_list = self._tokenize_words(text)
                self._build_char_model_from_words(word_list)
                self._save_model()
                print(f"âœ… ÄÃ£ há»c {len(word_list)} tá»« tá»« vÄƒn báº£n '{path}'.")
            except Exception as e:
                print(f"âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file: {e}")
            return True

        if command.startswith("dá»± Ä‘oÃ¡n tá»« "):
            prefix = command[len("dá»± Ä‘oÃ¡n tá»« "):].strip().lower()
            result = self._predict_word(prefix)
            if result != prefix:
                print(f"ğŸ”® Dá»± Ä‘oÃ¡n tá»« hoÃ n chá»‰nh: {result}")
            else:
                print("ğŸ¤· KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n.")
            return True

        return False